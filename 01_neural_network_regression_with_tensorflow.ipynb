{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNQWAE3hv8oZd7I+Kdtp6ym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/redrum88/tensorflow/blob/main/01_neural_network_regression_with_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps in modelling with TensorFlow\n",
        "* Get data ready (turn into tensors)\n",
        "* Build or pick a pretrained model (to suit your problem)\n",
        "* Fit the model to the data and make a prediction\n",
        "* Evaluate the model\n",
        "* Improve through experimentation\n",
        "* Save and reload your trained model\n"
      ],
      "metadata": {
        "id": "d5VWVe3VwUg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is regression problem?\n",
        "\n",
        "Example regression problems\n",
        "* How much will this house sell for?\n",
        "* How many people will buy this app?\n",
        "* How much will my health insurance be?\n",
        "* How much should i save each week for fuel?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Hm1qQroDFh4l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What we're going to cover\n",
        "* Architecture of a neural network regression model\n",
        "* Input shapes and output shapes of a regression model (features and labels)\n",
        "* Creating custom data to view and fit\n",
        "* Steps in modelling\n",
        "  * Creating a model\n",
        "  * Compiling a model\n",
        "  * Fitting a model\n",
        "  * Evaluating a model\n",
        "* Different evaluation methods\n",
        "* Saving and loading models"
      ],
      "metadata": {
        "id": "Hp_gbsYbIhUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "There are many definitions for a regression problem but in our case, we're going to simplify it: predicting a numerical variable based on some other combination of variables, even shorter... predicting a number.\n"
      ],
      "metadata": {
        "id": "qZgpyiRzIr_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlRqZadFOVzd",
        "outputId": "2f53046e-75e9-4a60-b37b-a37215c53334"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data to view and fit"
      ],
      "metadata": {
        "id": "SjEWUDXbOccw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create features\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create labels\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "2gewJZyoOwM4",
        "outputId": "3c16509a-08e9-407d-fb11-29fa7aa81988"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGqyFJZIPc4i",
        "outputId": "e1de875a-e6ca-490d-a7c2-95efa6bc202e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Input and output shapes"
      ],
      "metadata": {
        "id": "9UQdbfk3PzsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for our housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeQ5FbQOP48f",
        "outputId": "6ff200f5-4cae-4c43-c0e8-bc4838b8fa06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X.shape\n",
        "output_shape = y.shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbyVLVP5QcAV",
        "outputId": "6780dcae-5831-4428-e794-4f2028574cb8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((8,), (8,))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBKl_xsJQykP",
        "outputId": "202c6cfc-47ff-40cc-a3d7-f56e8c83cc9c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf2hkFxRRLTg",
        "outputId": "ab959726-e8ce-4916-9847-d76e2c76a02f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9NtMAKAR8GK",
        "outputId": "c013129b-cc27-40e4-c805-327590e8c62c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps i modelling with TensorFlow\n",
        "\n",
        "1. **Creating a model** - define the input and output layers, as well as the hidden layers of a deep learning model.\n",
        "2. **Compiling a model** - define the loss function (in other words, the function which tells our model how wrong it is) and the optimizer (tells our model how to improve the patterns its learning) and evaluation metrics (what we can use to interpret the performance of our mode).\n",
        "3.**Fitting a model** - letting the model try to find patters between X & y (features and labels)."
      ],
      "metadata": {
        "id": "klRBN2-WSIl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally, the first layer can receive an `input_shape` argument:\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Dense(8, input_shape(16,)))\n",
        "# Afterwards, we do automatic shape inference:\n",
        "model.add(tf.keras.layers.Dense(4))\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(8, input_shape=(16,)))\n",
        "\n",
        "model = tf.keras.Sequential\n",
        "model.add(tf.keras.layers.Dense(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "DCys2EbdVe6n",
        "outputId": "242cee38-e531-484c-99f4-a5cbcec4cd02"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2bf36928a6ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Optionally, the first layer can receive an `input_shape` argument:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Afterwards, we do automatic shape inference:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'TensorShape' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1. Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # sgd is short for stochasitc gradien descent\n",
        "              metrics=[\"mae\"]\n",
        "              )\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOH5UaP4TvPL",
        "outputId": "83927805-d4f0-422c-9b72-259318964b19"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 866ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f782c67e910>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our NumPy arrays into tensors dtype float32\n",
        "X = tf.cast(tf.constant(X), dtype=tf.float32)\n",
        "y = tf.cast(tf.constant(y), dtype=tf.float32)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTvyQNP3X2Jx",
        "outputId": "c9f09775-7be3-4924-bd86-0a7b36e8dc80"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQUPFASLYX3D",
        "outputId": "1bcb7ec0-21d7-4170-b0ab-6b7d68cf8d7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsxxnb6vZakH",
        "outputId": "39afaf26-43ae-4003-d56e-e1b7197e41c6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 69ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad4XtF4bZlG7",
        "outputId": "71a66bd8-6685-43de-b1db-7658e3cc30fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving our model\n",
        "\n",
        "We can improve our model, by altering the steps we took to create a model.\n",
        "\n",
        "1. **Creating a model** - here we might add more layers, increase the number of hidden units (all called neurons) within each of the hidden layers, change the activation function of each layer.\n",
        "2. **Compiling a model** - here we might change the optimization function or perhaps the **learning rate** of the optimization function.\n",
        "3. **Fitting a model** - here we might fit a model for more **epochs** (leave it training for longer) or on more data (give the model more examples to learn from)."
      ],
      "metadata": {
        "id": "ZGfSFuTZZ37q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's rebuild our model\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)\n",
        "# Before we trained with `5` epochs and now we'll train with increased epochs then before."
      ],
      "metadata": {
        "id": "4XUxh-pLpqFH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "632c69ab-6d31-4635-e513-3d67663b488e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 371ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2413 - mae: 7.2413\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9262 - mae: 6.9262\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f782c49aa00>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ct6ed7svuzn",
        "outputId": "6a2f34c1-eda7-4d44-89a4-bc1d391eb4a0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if our model's prediction has improved...\n",
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2OgqZQfzX97",
        "outputId": "66b0c0e1-0bf8-4fdd-cf10-a39451393753"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try add layer\n",
        "\n",
        "# Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(50, activation=None),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile a model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.01),\n",
        "              metrics=\"mae\")\n",
        "\n",
        "# Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keM2pwHV28eg",
        "outputId": "a10dfa9a-49a7-44ab-fd89-77efcb9bb88b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 12.3469 - mae: 12.3469\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.6170 - mae: 11.6170\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8836 - mae: 10.8836\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.1465 - mae: 10.1465\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4040 - mae: 9.4040\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.6532 - mae: 8.6532\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.8904 - mae: 7.8904\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.8174 - mae: 6.8174\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1412 - mae: 7.1412\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.4160 - mae: 7.4160\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7229 - mae: 7.7229\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7819 - mae: 7.7819\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.6396 - mae: 7.6396\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3494 - mae: 7.3494\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0025 - mae: 7.0025\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7269 - mae: 6.7269\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4364 - mae: 6.4364\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1431 - mae: 6.1431\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0919 - mae: 6.0919\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0366 - mae: 6.0366\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1774 - mae: 6.1774\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2158 - mae: 6.2158\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 6.1538 - mae: 6.1538\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0035 - mae: 6.0035\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7739 - mae: 5.7739\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.5313 - mae: 5.5313\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4211 - mae: 5.4211\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3081 - mae: 5.3081\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2965 - mae: 5.2965\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2780 - mae: 5.2780\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2141 - mae: 5.2141\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.1082 - mae: 5.1082\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9639 - mae: 4.9639\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7844 - mae: 4.7844\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5776 - mae: 4.5776\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4758 - mae: 4.4758\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3666 - mae: 4.3666\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2498 - mae: 4.2498\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1322 - mae: 4.1322\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9836 - mae: 3.9836\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8347 - mae: 3.8347\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6784 - mae: 3.6784\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5146 - mae: 3.5146\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3429 - mae: 3.3429\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1692 - mae: 3.1692\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9985 - mae: 2.9985\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.8128 - mae: 2.8128\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6285 - mae: 2.6285\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4338 - mae: 2.4338\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2284 - mae: 2.2284\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0123 - mae: 2.0123\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7852 - mae: 1.7852\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5469 - mae: 1.5469\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2971 - mae: 1.2971\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0368 - mae: 1.0368\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7763 - mae: 0.7763\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5450 - mae: 0.5450\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2720 - mae: 0.2720\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0769 - mae: 0.0769\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3692 - mae: 0.3692\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4942 - mae: 0.4942\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.5883 - mae: 0.5883\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7020 - mae: 0.7020\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6968 - mae: 0.6968\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7074 - mae: 0.7074\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6074 - mae: 0.6074\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5281 - mae: 0.5281\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.4097 - mae: 0.4097\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2870 - mae: 0.2870\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2768 - mae: 0.2768\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0607 - mae: 0.0607\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4016 - mae: 0.4016\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4353 - mae: 0.4353\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2602 - mae: 0.2602\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.3222 - mae: 0.3222\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2612 - mae: 0.2612\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2212 - mae: 0.2212\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1594 - mae: 0.1594\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0905 - mae: 0.0905\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1715 - mae: 0.1715\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1388 - mae: 0.1388\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2166 - mae: 0.2166\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1966 - mae: 0.1966\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1678 - mae: 0.1678\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1395 - mae: 0.1395\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.0455\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.1129 - mae: 0.1129\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1426 - mae: 0.1426\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1916 - mae: 0.1916\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1534 - mae: 0.1534\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1144 - mae: 0.1144\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0577 - mae: 0.0577\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1122 - mae: 0.1122\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1675 - mae: 0.1675\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1912 - mae: 0.1912\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1581 - mae: 0.1581\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1127 - mae: 0.1127\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1845 - mae: 0.1845\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0934 - mae: 0.0934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7805e55d90>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make prediction\n",
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ8SrWQg4Aaa",
        "outputId": "a59f5f28-8e20-4deb-baa3-cd1c03a44fcf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.209414]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see if we can make another to improve our model\n",
        "\n",
        "# Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(100, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=\"mae\")\n",
        "\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9r-9m7N4IyO",
        "outputId": "3c297460-6d8c-4bfd-eecb-86702026caee"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 302ms/step - loss: 13.2349 - mae: 13.2349\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.6529 - mae: 12.6529\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0684 - mae: 12.0684\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.4623 - mae: 11.4623\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8279 - mae: 10.8279\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.1402 - mae: 10.1402\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3665 - mae: 9.3665\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.4809 - mae: 8.4809\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4365 - mae: 7.4365\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2459 - mae: 6.2459\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8755 - mae: 4.8755\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9247 - mae: 3.9247\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0318 - mae: 4.0318\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9355 - mae: 3.9355\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9940 - mae: 3.9940\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9469 - mae: 3.9469\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9554 - mae: 3.9554\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9586 - mae: 3.9586\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9159 - mae: 3.9159\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9703 - mae: 3.9703\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8742 - mae: 3.8742\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9861 - mae: 3.9861\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8631 - mae: 3.8631\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9731 - mae: 3.9731\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8837 - mae: 3.8837\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9311 - mae: 3.9311\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8993 - mae: 3.8993\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8899 - mae: 3.8899\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9128 - mae: 3.9128\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8479 - mae: 3.8479\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9264 - mae: 3.9264\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8185 - mae: 3.8185\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9602 - mae: 3.9602\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8279 - mae: 3.8279\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.9026 - mae: 3.9026\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8419 - mae: 3.8419\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8601 - mae: 3.8601\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8564 - mae: 3.8564\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8168 - mae: 3.8168\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8714 - mae: 3.8714\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7885 - mae: 3.7885\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9054 - mae: 3.9054\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7752 - mae: 3.7752\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 3.8673 - mae: 3.8673\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7903 - mae: 3.7903\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8235 - mae: 3.8235\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8059 - mae: 3.8059\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7786 - mae: 3.7786\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8220 - mae: 3.8220\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7493 - mae: 3.7493\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8576 - mae: 3.8576\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7289 - mae: 3.7289\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8260 - mae: 3.8260\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7446 - mae: 3.7446\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7801 - mae: 3.7801\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7608 - mae: 3.7608\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7333 - mae: 3.7333\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7776 - mae: 3.7776\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7006 - mae: 3.7006\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8140 - mae: 3.8140\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6866 - mae: 3.6866\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7765 - mae: 3.7765\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.7029 - mae: 3.7029\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7284 - mae: 3.7284\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7198 - mae: 3.7198\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6793 - mae: 3.6793\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7373 - mae: 3.7373\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6434 - mae: 3.6434\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7742 - mae: 3.7742\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6478 - mae: 3.6478\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7173 - mae: 3.7173\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6652 - mae: 3.6652\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6672 - mae: 3.6672\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6834 - mae: 3.6834\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6162 - mae: 3.6162\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7021 - mae: 3.7021\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5899 - mae: 3.5899\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7018 - mae: 3.7018\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6156 - mae: 3.6156\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6500 - mae: 3.6500\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6336 - mae: 3.6336\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5962 - mae: 3.5962\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6514 - mae: 3.6514\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5415 - mae: 3.5415\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6715 - mae: 3.6715\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5569 - mae: 3.5569\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6268 - mae: 3.6268\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5870 - mae: 3.5870\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5720 - mae: 3.5720\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6067 - mae: 3.6067\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5166 - mae: 3.5166\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6270 - mae: 3.6270\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5056 - mae: 3.5056\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.6027 - mae: 3.6027\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5443 - mae: 3.5443\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5436 - mae: 3.5436\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5644 - mae: 3.5644\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4865 - mae: 3.4865\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5839 - mae: 3.5839\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4625 - mae: 3.4625\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99a1cc5e50>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GTK6d9o5yc4",
        "outputId": "d1bc394c-a5e0-4570-85aa-d94991bfd31f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 55ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.290323]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's remind ourselves of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1qWIN-H6wQh",
        "outputId": "b4dbbbb5-3422-458b-a0cf-f57229412378"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's try to make a prediction\n",
        "model.predict([17.])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieBAMKbe84_x",
        "outputId": "fe8ad6e1-7d3b-4c51-9064-0aad5625f2fb"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30.290323]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common ways to improve a deep model:\n",
        "* Adding layers\n",
        "* Increase the number of hidden units\n",
        "* Change the activation functions\n",
        "* Change the optimization function\n",
        "* Change the learning rate\n",
        "* Fitting on more data"
      ],
      "metadata": {
        "id": "8tnXm7H48_rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a model\n",
        "\n",
        "In practice, a typical workflow you'll go through when building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it -> tweak a model -> fit it -> evaluate it...\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R4NssOQh_Vel"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation.. there are 3 words you should memorize:\n",
        "> \"Visualize, visualize, visualize\"\n",
        "\n",
        "It's a good idea to visualize:\n",
        "* The data - what data are we working with? what does it look like?\n",
        "* The model itself - what does our model look like?\n",
        "* The training of a model = how does a model perform while it learns?\n",
        "* The predictions of the model - how do the predictions of a model line up against  the ground truth (the original labels)?"
      ],
      "metadata": {
        "id": "8CFLxbpZAo-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIYgy6H1A3fd",
        "outputId": "9e318936-816d-4f0c-ccf1-0fcc4f2e5681"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEcS8r4ABwy0",
        "outputId": "67ddbeed-0b8e-479a-89e8-c721a0fc2ab7"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "N3qRZZmQB9Ji",
        "outputId": "41b53b95-6bb1-4735-9af7-8593d68970bb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training set** - the model learns from this data, which is typically 7-80% of the total data you have available.\n",
        "* **Validation set** - the model gets tuned on this data, which is typically 10-15% of the data available.\n",
        "* **Test set** - the model gets evaluated on this data to test what is has learned, this set is typically 10-15% of the total data available."
      ],
      "metadata": {
        "id": "U2hVXCLsCJv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lenght of how many samples we have\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9jxx25dF7wh",
        "outputId": "c5a6f110-2b57-488f-8c8f-2e07ccf6620a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and test sets\n",
        "X_train = X[:40] # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]\n",
        "\n",
        "X_test = X[40:] # last 10 are testing samples (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPFkACq9GEPF",
        "outputId": "82d22dbf-8a6e-4a14-d0d2-3878846b3cdc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now we've got our data in training and test sets... let's visualize it again!"
      ],
      "metadata": {
        "id": "rfbfT3C1D_Mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 8))\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label=\"Training data\")\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label=\"Testing data\")\n",
        "# Show a legend\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "oddnEUoTHqks",
        "outputId": "64f31a95-a129-471b-f8a1-088253971a1e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's have a look at how to build a neural network for our data\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=\"mae\")\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)\n",
        "#model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUlRKe0VIKdP",
        "outputId": "ba92a616-6d5c-45a4-8873-035679b67f69"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.6477 - mae: 20.6477\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5278 - mae: 9.5278\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2127 - mae: 11.2127\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6034 - mae: 9.6034\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5184 - mae: 10.5184\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7389 - mae: 9.7389\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8284 - mae: 8.8284\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0662 - mae: 9.0662\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.3971 - mae: 19.3971\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.4734 - mae: 10.4734\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5380 - mae: 8.5380\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9682 - mae: 10.9682\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.5696 - mae: 7.5696\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.9642 - mae: 15.9642\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.0409 - mae: 13.0409\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9317 - mae: 7.9317\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.2403 - mae: 11.2403\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.2725 - mae: 10.2725\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.4889 - mae: 19.4889\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.1428 - mae: 16.1428\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0438 - mae: 12.0438\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6438 - mae: 8.6438\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6735 - mae: 9.6735\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5756 - mae: 8.5756\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5715 - mae: 11.5715\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.1573 - mae: 15.1573\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0446 - mae: 12.0446\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.3362 - mae: 13.3362\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5961 - mae: 9.5961\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.1179 - mae: 17.1179\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.9349 - mae: 22.9349\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9117 - mae: 7.9117\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.0915 - mae: 14.0915\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3271 - mae: 12.3271\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.2716 - mae: 8.2716\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5023 - mae: 10.5023\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1426 - mae: 10.1426\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.3519 - mae: 11.3519\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.7141 - mae: 14.7141\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8447 - mae: 12.8447\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2296 - mae: 9.2296\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0264 - mae: 11.0264\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.3346 - mae: 8.3346\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0910 - mae: 13.0910\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6300 - mae: 13.6300\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.2573 - mae: 8.2573\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7394 - mae: 8.7394\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0460 - mae: 10.0460\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5250 - mae: 8.5250\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0346 - mae: 9.0346\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3781 - mae: 9.3781\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.0623 - mae: 14.0623\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.3899 - mae: 15.3899\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.8990 - mae: 10.8990\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.4215 - mae: 15.4215\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1156 - mae: 9.1156\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6973 - mae: 9.6973\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0021 - mae: 9.0021\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2379 - mae: 10.2379\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1639 - mae: 8.1639\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0306 - mae: 10.0306\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0334 - mae: 7.0334\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6693 - mae: 12.6693\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6126 - mae: 12.6126\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4361 - mae: 9.4361\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.5012 - mae: 11.5012\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.0362 - mae: 8.0362\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5637 - mae: 8.5637\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2592 - mae: 12.2592\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9562 - mae: 8.9562\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9321 - mae: 9.9321\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9698 - mae: 9.9698\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4430 - mae: 12.4430\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.5592 - mae: 10.5592\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.6295 - mae: 9.6295\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0969 - mae: 11.0969\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.2780 - mae: 8.2780\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9714 - mae: 8.9714\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.7696 - mae: 19.7696\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.8272 - mae: 17.8272\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0675 - mae: 7.0675\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.4080 - mae: 10.4080\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.8329 - mae: 9.8329\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.9276 - mae: 7.9276\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4345 - mae: 9.4345\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4803 - mae: 9.4803\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.4227 - mae: 11.4227\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9207 - mae: 9.9207\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2456 - mae: 7.2456\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6790 - mae: 12.6790\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.3017 - mae: 7.3017\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.6640 - mae: 7.6640\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.1122 - mae: 7.1122\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.5278 - mae: 12.5278\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9032 - mae: 9.9032\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1393 - mae: 9.1393\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0931 - mae: 12.0931\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0497 - mae: 9.0497\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.4954 - mae: 8.4954\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.4750 - mae: 14.4750\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7804fa6400>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the model"
      ],
      "metadata": {
        "id": "8FOLMS8eJk1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqsGIRX-KbsC",
        "outputId": "05985f4f-0850-47a8-e7e1-fc4877f60ecb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_17 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a model which builds automatically by defining the input_shape argument\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model \n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(1, input_shape=[1])\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.SGD(),\n",
        "              metrics=[\"mae\"])\n"
      ],
      "metadata": {
        "id": "4GsQxJSdKg1F"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JggDOtvpLPxH",
        "outputId": "dd4cbb7e-36e9-4394-f72f-68d230d3db28"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Total params** - total number of parameters in the model.\n",
        "* **Trainable parameters** - these are the parameters (patters) the model can update as it trains.\n",
        "* Non-trainable params - these parameters aren't updated during training (this is typical when you bring in already learn patters or parameters from other models during **transfer learning**)\n",
        "\n",
        "📖**Resource:** For a more in-depth overview of the trainable parameters within a layer, check out MIT's introduction to deep learning video.\n",
        "\n",
        "⚒️**Exercise:** Try playing around with the number of hidden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`"
      ],
      "metadata": {
        "id": "HxHJKUfxLrm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's fit our model to the training data\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYch0n8hMScx",
        "outputId": "80230357-7898-4513-ee6d-aaacf81ce58c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7804fbac10>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAWB85ftPKMK",
        "outputId": "ac52333e-69e4-4dc6-ec0a-e742f4cd647b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zySAQwMiPUnf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}